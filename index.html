<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Varun Kumar


</title>
<meta name="description" content="Varun Kumar's Personal Webpage.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üë®‚Äçüíª</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-72063134-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-72063134-1');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <!--  -->
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     Varun Kumar
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <p>Hi, My name is Varun. I am currently a Senior Applied Scientist at Alexa Natural Language Understanding (NLU). At Alexa, I broadly work on</p>

<ul>
  <li>
<strong>NLU Robustness</strong>: How to make sure that Alexa NLU performs consistently under unexpected data changes (GDPR data deletion), distribution shifts, model retraining, etc.</li>
  <li>
<strong>Data generation/augmentation</strong>: How to generate training data for new features, existing low-resource functionalities. How do we make sure that the generated data is fair?</li>
  <li>
<strong>Data Pipelines</strong>: How to select diverse labeled/unlabeled data for Alexa model training.</li>
</ul>

<p>My Amazon related blogs/papers can be found at <a href="https://www.amazon.science/author/varun-kumar" target="_blank" rel="noopener noreferrer">Amazon Science</a>
website.</p>

<p><strong>Not-So-Distant Past</strong></p>

<p>I graduated from <a href="https://www.cs.umd.edu" target="_blank" rel="noopener noreferrer">University Of Maryland, College Park (UMD)</a> in 2017. At UMD, I primarily worked on the <a href="https://users.umiacs.umd.edu/~jbg/projects/IIS-1409287.html" target="_blank" rel="noopener noreferrer">Human-In-The-Loop topic modeling</a> project to incorporate non-experts feedback into topic modeling. Before joining UMD, I worked as a software engineer at <a href="https://en.wikipedia.org/wiki/Tata_Research_Development_and_Design_Centre" target="_blank" rel="noopener noreferrer">Tata Research Development and Design Centre (TRDDC)</a>, India for 3.5 years.</p>


    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Feb 24, 2022</th>
          <td>
            
              2 Papers (1 long paper on bias mitigation and 1 short paper on fairness metrics analysis) accepted at ACL 2022

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 11, 2021</th>
          <td>
            
              Amazon‚Äôs SVP Rohit‚Äôs <a href="https://www.amazon.science/blog/alexa-the-science-must-go-on" target="_blank" rel="noopener noreferrer">blog post</a> about latest Alexa research highlighting 2 papers that I co-authored.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Mar 1, 2021</th>
          <td>
            
              <a href="https://venturebeat.com/2021/02/03/researchers-release-dataset-to-expose-racial-religious-and-gender-biases-in-language-models/" target="_blank" rel="noopener noreferrer">VentureBeat.com coverage</a> of our BOLD paper. Dataset is available at <a href="https://github.com/amazon-research/bold" target="_blank" rel="noopener noreferrer">Amazon-Research‚Äôs github repo</a>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 28, 2021</th>
          <td>
            
              <a href="https://aclanthology.org/2020.lifelongnlp-1.3.pdf" target="_blank" rel="noopener noreferrer">Data Augmentation using pre-trained models</a> paper‚Äôs code is available at <a href="https://github.com/varunkumar-dev/TransformersDataAugmentation" target="_blank" rel="noopener noreferrer">Github</a>

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kumar-etal-2020-data" class="col-sm-8">
    
      <div class="title">Data Augmentation using Pre-trained Transformer Models</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Choudhary, Ashutosh,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Cho, Eunah
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2nd Workshop on Life-long Learning for Spoken Language Systems</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Language model based pre-trained models such as BERT have provided significant gains across different NLP tasks. In this paper, we study different types of transformer based pre-trained models such as auto-regressive models (GPT-2), auto-encoder models (BERT), and seq2seq models (BART) for conditional data augmentation. We show that prepending the class labels to text sequences provides a simple yet effective way to condition the pre-trained models for data augmentation. Additionally, on three classification benchmarks, pre-trained Seq2Seq model outperforms other data augmentation methods in a low-resource setting. Further, we explore how different pre-trained model based data augmentation differs in-terms of data diversity, and how well such methods preserve the class-label information.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="10.1145/3442188.3445924" class="col-sm-8">
    
      <div class="title">BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Dhamala, Jwala,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sun, Tony,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krishna, Satyapriya,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Pruksachatkun, Yada,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chang, Kai-Wei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gupta, Rahul
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent advances in deep learning techniques have enabled machines to generate cohesive
open-ended text when prompted with a sequence of words as context. While these models
now empower many downstream applications from conversation bots to automatic storytelling,
they have been shown to generate texts that exhibit social biases. To systematically
study and benchmark social biases in open-ended language generation, we introduce
the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that
consists of 23,679 English text generation prompts for bias benchmarking across five
domains: profession, gender, race, religion, and political ideology. We also propose
new automated metrics for toxicity, psycholinguistic norms, and text gender polarity
to measure social biases in open-ended text generation from multiple angles. An examination
of text generated from three popular language models reveals that the majority of
these models exhibit a larger social bias than human-written Wikipedia text across
all domains. With these results we highlight the need to benchmark biases in open-ended
language generation and caution users of language generation models on downstream
tasks to be cognizant of these embedded prejudices.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%6B.%76%61%72%75%6E@%6F%75%74%6C%6F%6F%6B.%63%6F%6D"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=d-La2lQAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/varunkumar-dev" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/varunin" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/varun_kr" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>



<a href="https://www.amazon.science/author/varun-kumar" title="Work" target="_blank" rel="noopener noreferrer"><i class="fas fa-briefcase"></i></a>









      </div>
      <div class="contact-note">If you want to chat, shoot me an email. 
</div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    ¬© Copyright 2022 Varun  Kumar.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: March 25, 2022.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
