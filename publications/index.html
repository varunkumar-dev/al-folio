<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Varun Kumar


  | publications

</title>
<meta name="description" content="Varun Kumar's Personal Webpage.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üë®‚Äçüíª</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-72063134-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-72063134-1');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://varunkumar-dev.github.io/">
       Varun Kumar
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <!--  -->
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Gupta2022MitigatingGB" class="col-sm-8">
    
      <div class="title">Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Gupta, Umang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dhamala, J.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Verma, Apurv,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Pruksachatkun, Yada,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krishna, Satyapriya,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gupta, Rahul,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chang, Kai-Wei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Steeg, Greg Ver,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Galstyan, A. G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics Findings</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Language models excel at generating coherent text, and model compression techniques such as knowledge distillation have enabled their use in resource-constrained settings. However, these models can be biased in multiple ways, including the unfounded association of male and female genders with gender-neutral professions. Therefore, knowledge distillation without any fairness constraints may preserve or exaggerate the teacher model‚Äôs biases onto the distilled model. To this end, we present a novel approach to mitigate gender disparity in text generation by learning a fair model during knowledge distillation. We propose two modifications to the base knowledge distillation based on counterfactual role reversal‚Äî modifying teacher probabilities and augmenting the training set. We evaluate gender polarity across professions in open-ended text generated from the resulting distilled and finetuned GPT‚Äì2 models and demonstrate a substantial reduction in gender disparity with only a minor compromise in utility. Finally, we observe that language models that reduce gender polarity in language generation do not improve embedding fairness or downstream classification fairness.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Cao2022Intrinsic" class="col-sm-8">
    
      <div class="title">On the intrinsic and extrinsic fairness evaluation metrics for contextualized language representations</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Cao, Yang Trista,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Pruksachatkun, Yada,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chang, Kai-Wei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gupta, Rahul,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dhamala, Jwala,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Galstyan, Aram
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Multiple metrics have been introduced to measure fairness in various natural language processing tasks. These metrics can be roughly categorized into two categories: 1) extrinsic metrics for evaluating fairness in downstream applications and 2) intrinsic metrics for estimating fairness in upstream contextualized language representation models. In this paper, we conduct an extensive correlation study between intrinsic and extrinsic metrics across bias notions using 19 contextualized language models. We find that intrinsic and extrinsic metrics do not necessarily correlate in their original setting, even when correcting for metric misalignments, noise in evaluation datasets, and confounding factors such as experiment configuration for extrinsic metrics. </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="chen-etal-2021-industry" class="col-sm-8">
    
      <div class="title">Industry Scale Semi-Supervised Learning for Natural Language Understanding</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Chen, Luoxin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Garcia, Francisco,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xie, He,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lu, Jianhua
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper presents a production Semi-Supervised Learning (SSL) pipeline based on the student-teacher framework, which leverages millions of unlabeled examples to improve Natural Language Understanding (NLU) tasks. We investigate two questions related to the use of unlabeled data in production SSL context: 1) how to select samples from a huge unlabeled data pool that are beneficial for SSL training, and 2) how does the selected data affect the performance of different state-of-the-art SSL techniques. We compare four widely used SSL techniques, Pseudo-label (PL), Knowledge Distillation (KD), Virtual Adversarial Training (VAT) and Cross-View Training (CVT) in conjunction with two data selection methods including committee-based selection and submodular optimization based selection. We further examine the benefits and drawbacks of these techniques when applied to intent classification (IC) and named entity recognition (NER) tasks, and provide guidelines specifying when each of these methods might be beneficial to improve large scale NLU systems.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="10.1145/3442188.3445924" class="col-sm-8">
    
      <div class="title">BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Dhamala, Jwala,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sun, Tony,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krishna, Satyapriya,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Pruksachatkun, Yada,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chang, Kai-Wei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gupta, Rahul
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent advances in deep learning techniques have enabled machines to generate cohesive
open-ended text when prompted with a sequence of words as context. While these models
now empower many downstream applications from conversation bots to automatic storytelling,
they have been shown to generate texts that exhibit social biases. To systematically
study and benchmark social biases in open-ended language generation, we introduce
the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that
consists of 23,679 English text generation prompts for bias benchmarking across five
domains: profession, gender, race, religion, and political ideology. We also propose
new automated metrics for toxicity, psycholinguistic norms, and text gender polarity
to measure social biases in open-ended text generation from multiple angles. An examination
of text generated from three popular language models reveals that the majority of
these models exhibit a larger social bias than human-written Wikipedia text across
all domains. With these results we highlight the need to benchmark biases in open-ended
language generation and caution users of language generation models on downstream
tasks to be cognizant of these embedded prejudices.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="9383495" class="col-sm-8">
    
      <div class="title">Protoda: Efficient Transfer Learning for Few-Shot Intent Classification</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Kumar, Manoj,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Glaude, Hadrien,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lichy, Cyprien,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Alok, Aman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gupta, Rahul
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2021 IEEE Spoken Language Technology Workshop (SLT)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Practical sequence classification tasks in natural language processing often suffer from low training data availability for target classes. Recent works towards mitigating this problem have focused on transfer learning using embeddings pre-trained on often unrelated tasks, for instance, language modeling. We adopt an alternative approach by transfer learning on an ensemble of related tasks using prototypical networks under the meta-learning paradigm. Using intent classification as a case study, we demonstrate that increasing variability in training tasks can significantly improve classification performance. Further, we apply data augmentation in conjunction with meta-learning to reduce sampling bias. We make use of a conditional generator for data augmentation that is trained directly using the meta-learning objective and simultaneously with prototypical networks, hence ensuring that data augmentation is customized to the task. We explore augmentation in the sentence embedding space as well as prototypical embedding space. Combining meta-learning with augmentation provides upto 6.49% and 8.53% relative F1-score improvements over the best performing systems in the 5-shot and 10-shot learning, respectively. </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kumar-etal-2020-data" class="col-sm-8">
    
      <div class="title">Data Augmentation using Pre-trained Transformer Models</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Choudhary, Ashutosh,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Cho, Eunah
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2nd Workshop on Life-long Learning for Spoken Language Systems</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Language model based pre-trained models such as BERT have provided significant gains across different NLP tasks. In this paper, we study different types of transformer based pre-trained models such as auto-regressive models (GPT-2), auto-encoder models (BERT), and seq2seq models (BART) for conditional data augmentation. We show that prepending the class labels to text sequences provides a simple yet effective way to condition the pre-trained models for data augmentation. Additionally, on three classification benchmarks, pre-trained Seq2Seq model outperforms other data augmentation methods in a low-resource setting. Further, we explore how different pre-trained model based data augmentation differs in-terms of data diversity, and how well such methods preserve the class-label information.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="10.1145/3377325.3377491" class="col-sm-8">
    
      <div class="title">Digging into User Control: Perceptions of Adherence and Instability in Transparent Models</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Smith-Renner, Alison,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Boyd-Graber, Jordan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Seppi, Kevin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Findlater, Leah
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 25th International Conference on Intelligent User Interfaces</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We explore predictability and control in interactive systems where controls are easy
to validate. Human-in-the-loop techniques allow users to guide unsupervised algorithms
by exposing and supporting interaction with underlying model representations, increasing
transparency and promising fine-grained control. However, these models must balance
user input and the underlying data, meaning they sometimes update slowly, poorly,
or unpredictably‚Äîeither by not incorporating user input as expected (adherence)
or by making other unexpected changes (instability). While prior work exposes model
internals and supports user feedback, less attention has been paid to users‚Äô reactions
when transparent models limit control. Focusing on interactive topic models, we explore
user perceptions of control using a study where 100 participants organize documents
with one of three distinct topic modeling approaches. These approaches incorporate
input differently, resulting in varied adherence, stability, update speeds, and model
quality. Participants disliked slow updates most, followed by lack of adherence. Instability
was polarizing: some participants liked it when it surfaced interesting information,
while others did not. Across modeling approaches, participants differed only in whether
they noticed adherence.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kumar-etal-2019-closer" class="col-sm-8">
    
      <div class="title">A Closer Look At Feature Space Data Augmentation For Few-Shot Intent Classification</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Glaude, Hadrien,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lichy, Cyprien,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Campbell, Wlliam
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>New conversation topics and functionalities are constantly being added to conversational AI agents like Amazon Alexa and Apple Siri. As data collection and annotation is not scalable and is often costly, only a handful of examples for the new functionalities are available, which results in poor generalization performance. We formulate it as a Few-Shot Integration (FSI) problem where a few examples are used to introduce a new intent. In this paper, we study six feature space data augmentation methods to improve classification performance in FSI setting in combination with both supervised and unsupervised representation learning methods such as BERT. Through realistic experiments on two public conversational datasets, SNIPS, and the Facebook Dialog corpus, we show that data augmentation in feature space provides an effective way to improve intent classification performance in few-shot setting beyond traditional transfer learning approaches. In particular, we show that (a) upsampling in latent space is a competitive baseline for feature space augmentation (b) adding the difference between two examples to a new example is a simple yet effective data augmentation method.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kumar-etal-2019-didnt" class="col-sm-8">
    
      <div class="title">Why Didn‚Äôt You Listen to Me? Comparing User Control of Human-in-the-Loop Topic Models</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Smith-Renner, Alison,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Findlater, Leah,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Seppi, Kevin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Boyd-Graber, Jordan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>To address the lack of comparative evaluation of Human-in-the-Loop Topic Modeling (HLTM) systems, we implement and evaluate three contrasting HLTM modeling approaches using simulation experiments. These approaches extend previously proposed frameworks, including constraints and informed prior-based methods. Users should have a sense of control in HLTM systems, so we propose a control metric to measure whether refinement operations‚Äô results match users‚Äô expectations. Informed prior-based methods provide better control than constraints, but constraints yield higher quality topics.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="9003747" class="col-sm-8">
    
      <div class="title">Efficient Semi-Supervised Learning for Natural Language Understanding by Optimizing Diversity</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Cho, Eunah,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xie, He,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lalor, John P.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Campbell, William M.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Expanding new functionalities efÔ¨Åciently is an ongoing challenge for single-turn task-oriented dialogue systems. In this work, we explore functionality-speciÔ¨Åc semi-supervised learning via self-training. We consider methods that augment training data automatically from unlabeled data sets in a functionality-targeted manner. In addition, we examine multiple techniques for efÔ¨Åcient selection of augmented utterances to reduce training time and increase diversity. First, we consider paraphrase detection methods that attempt to Ô¨Ånd utterance variants of labeled training data with good coverage. Second, we explore sub-modular optimization based on n-grams features for utterance selection. Experiments show that functionality-speciÔ¨Åc self-training is very effective for improving system performance. In addition, methods optimizing diversity can reduce training data in many cases to 50% with little impact on performance. </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="10.1145/3172944.3172965" class="col-sm-8">
    
      <div class="title">Closing the Loop: User-Centered Design and Evaluation of a Human-in-the-Loop Topic Modeling System</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Smith, Alison,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Boyd-Graber, Jordan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Seppi, Kevin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Findlater, Leah
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 23rd International Conference on Intelligent User Interfaces</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Human-in-the-loop topic modeling allows users to guide the creation of topic models
and to improve model quality without having to be experts in topic modeling algorithms.
Prior work in this area has focused either on algorithmic implementation without understanding
how users actually wish to improve the model or on user needs but without the context
of a fully interactive system. To address this disconnect, we implemented a set of
model refinements requested by users in prior work and conducted a study with twelve
non-expert participants to examine how end users are affected by issues that arise
with a fully interactive, user-centered system. As these issues mirror those identified
in interactive machine learning more broadly, such as unpredictability, latency, and
trust, we also examined interactive machine learning challenges with non-expert end
users through the lens of human-in-the-loop topic modeling. We found that although
users experience unpredictability, their reactions vary from positive to negative,
and, surprisingly, we did not find any cases of distrust, but instead noted instances
where users perhaps trusted the system too much or had too little confidence in themselves.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="zirikly-etal-2016-gw" class="col-sm-8">
    
      <div class="title">The GW/UMD CLPsych 2016 Shared Task System</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Zirikly, Ayah,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Resnik, Philip
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="10.1145/2818052.2869096" class="col-sm-8">
    
      <div class="title">Mining Shapes of Expertise in Online Social Q&amp;A Communities</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kumar, Varun</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Pedanekar, Niranjan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing Companion</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Expertise of an individual is metaphorically defined by shapes of letters such as
I, T, M and hyphen, depending on her expertise in an area (depth) and the number of
areas of interest (width). Industries have now started recruiting people with specific
shapes of expertise. In this poster, we introduce the idea of mining shapes of user
expertise in a typical online social Question and Answer (Q&amp;A) community where expert
users often answer questions posed by other users. We report observations on distribution
of different shapes of expertise in a StackExchange community called Super User.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    ¬© Copyright 2022 Varun  Kumar.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: March 25, 2022.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
