---
---

@string{aps = {American Physical Society,}}


@inproceedings{kumar-etal-2020-data,
    title = "Data Augmentation using Pre-trained Transformer Models",
    author = "Kumar, Varun  and
      Choudhary, Ashutosh  and
      Cho, Eunah",
    booktitle = "Proceedings of the 2nd Workshop on Life-long Learning for Spoken Language Systems",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.lifelongnlp-1.3",
    pages = "18--26",
    selected={true},
    abstract = "Language model based pre-trained models such as BERT have provided significant gains across different NLP tasks. In this paper, we study different types of transformer based pre-trained models such as auto-regressive models (GPT-2), auto-encoder models (BERT), and seq2seq models (BART) for conditional data augmentation. We show that prepending the class labels to text sequences provides a simple yet effective way to condition the pre-trained models for data augmentation. Additionally, on three classification benchmarks, pre-trained Seq2Seq model outperforms other data augmentation methods in a low-resource setting. Further, we explore how different pre-trained model based data augmentation differs in-terms of data diversity, and how well such methods preserve the class-label information.",
}

@inproceedings{chen-etal-2021-industry,
    title = "Industry Scale Semi-Supervised Learning for Natural Language Understanding",
    author = "Chen, Luoxin  and
      Garcia, Francisco  and
      Kumar, Varun  and
      Xie, He  and
      Lu, Jianhua",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-industry.39",
    doi = "10.18653/v1/2021.naacl-industry.39",
    pages = "311--318",
    selected={true},
    abstract = "This paper presents a production Semi-Supervised Learning (SSL) pipeline based on the student-teacher framework, which leverages millions of unlabeled examples to improve Natural Language Understanding (NLU) tasks. We investigate two questions related to the use of unlabeled data in production SSL context: 1) how to select samples from a huge unlabeled data pool that are beneficial for SSL training, and 2) how does the selected data affect the performance of different state-of-the-art SSL techniques. We compare four widely used SSL techniques, Pseudo-label (PL), Knowledge Distillation (KD), Virtual Adversarial Training (VAT) and Cross-View Training (CVT) in conjunction with two data selection methods including committee-based selection and submodular optimization based selection. We further examine the benefits and drawbacks of these techniques when applied to intent classification (IC) and named entity recognition (NER) tasks, and provide guidelines specifying when each of these methods might be beneficial to improve large scale NLU systems.",
}

@inproceedings{kumar-etal-2019-closer,
    title = "A Closer Look At Feature Space Data Augmentation For Few-Shot Intent Classification",
    author = "Kumar, Varun  and
      Glaude, Hadrien  and
      de Lichy, Cyprien  and
      Campbell, Wlliam",
    booktitle = "Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-6101",
    doi = "10.18653/v1/D19-6101",
    pages = "1--10",
    abstract = "New conversation topics and functionalities are constantly being added to conversational AI agents like Amazon Alexa and Apple Siri. As data collection and annotation is not scalable and is often costly, only a handful of examples for the new functionalities are available, which results in poor generalization performance. We formulate it as a Few-Shot Integration (FSI) problem where a few examples are used to introduce a new intent. In this paper, we study six feature space data augmentation methods to improve classification performance in FSI setting in combination with both supervised and unsupervised representation learning methods such as BERT. Through realistic experiments on two public conversational datasets, SNIPS, and the Facebook Dialog corpus, we show that data augmentation in feature space provides an effective way to improve intent classification performance in few-shot setting beyond traditional transfer learning approaches. In particular, we show that (a) upsampling in latent space is a competitive baseline for feature space augmentation (b) adding the difference between two examples to a new example is a simple yet effective data augmentation method.",
}

@inproceedings{kumar-etal-2019-didnt,
    title = "Why Didn{'}t You Listen to Me? Comparing User Control of Human-in-the-Loop Topic Models",
    author = "Kumar, Varun  and
      Smith-Renner, Alison  and
      Findlater, Leah  and
      Seppi, Kevin  and
      Boyd-Graber, Jordan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1637",
    doi = "10.18653/v1/P19-1637",
    pages = "6323--6330",
    abstract = "To address the lack of comparative evaluation of Human-in-the-Loop Topic Modeling (HLTM) systems, we implement and evaluate three contrasting HLTM modeling approaches using simulation experiments. These approaches extend previously proposed frameworks, including constraints and informed prior-based methods. Users should have a sense of control in HLTM systems, so we propose a control metric to measure whether refinement operations{'} results match users{'} expectations. Informed prior-based methods provide better control than constraints, but constraints yield higher quality topics.",
}

@inproceedings{zirikly-etal-2016-gw,
    title = "The {GW}/{UMD} {CLP}sych 2016 Shared Task System",
    author = "Zirikly, Ayah  and
      Kumar, Varun  and
      Resnik, Philip",
    booktitle = "Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology",
    month = jun,
    year = "2016",
    address = "San Diego, CA, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-0321",
    doi = "10.18653/v1/W16-0321",
    pages = "166--170",
}
@inproceedings{10.1145/3172944.3172965,
author = {Smith, Alison and Kumar, Varun and Boyd-Graber, Jordan and Seppi, Kevin and Findlater, Leah},
title = {Closing the Loop: User-Centered Design and Evaluation of a Human-in-the-Loop Topic Modeling System},
year = {2018},
isbn = {9781450349451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3172944.3172965},
doi = {10.1145/3172944.3172965},
abstract = {Human-in-the-loop topic modeling allows users to guide the creation of topic models
and to improve model quality without having to be experts in topic modeling algorithms.
Prior work in this area has focused either on algorithmic implementation without understanding
how users actually wish to improve the model or on user needs but without the context
of a fully interactive system. To address this disconnect, we implemented a set of
model refinements requested by users in prior work and conducted a study with twelve
non-expert participants to examine how end users are affected by issues that arise
with a fully interactive, user-centered system. As these issues mirror those identified
in interactive machine learning more broadly, such as unpredictability, latency, and
trust, we also examined interactive machine learning challenges with non-expert end
users through the lens of human-in-the-loop topic modeling. We found that although
users experience unpredictability, their reactions vary from positive to negative,
and, surprisingly, we did not find any cases of distrust, but instead noted instances
where users perhaps trusted the system too much or had too little confidence in themselves.},
booktitle = {23rd International Conference on Intelligent User Interfaces},
pages = {293–304},
numpages = {12},
location = {Tokyo, Japan},
series = {IUI '18}
}

@inproceedings{10.1145/3377325.3377491,
author = {Smith-Renner, Alison and Kumar, Varun and Boyd-Graber, Jordan and Seppi, Kevin and Findlater, Leah},
title = {Digging into User Control: Perceptions of Adherence and Instability in Transparent Models},
year = {2020},
isbn = {9781450371186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377325.3377491},
doi = {10.1145/3377325.3377491},
abstract = {We explore predictability and control in interactive systems where controls are easy
to validate. Human-in-the-loop techniques allow users to guide unsupervised algorithms
by exposing and supporting interaction with underlying model representations, increasing
transparency and promising fine-grained control. However, these models must balance
user input and the underlying data, meaning they sometimes update slowly, poorly,
or unpredictably---either by not incorporating user input as expected (adherence)
or by making other unexpected changes (instability). While prior work exposes model
internals and supports user feedback, less attention has been paid to users' reactions
when transparent models limit control. Focusing on interactive topic models, we explore
user perceptions of control using a study where 100 participants organize documents
with one of three distinct topic modeling approaches. These approaches incorporate
input differently, resulting in varied adherence, stability, update speeds, and model
quality. Participants disliked slow updates most, followed by lack of adherence. Instability
was polarizing: some participants liked it when it surfaced interesting information,
while others did not. Across modeling approaches, participants differed only in whether
they noticed adherence.},
booktitle = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
pages = {519–530},
numpages = {12},
keywords = {topic modeling, interactive machine learning, intelligent user interface evaluation, control, transparency},
location = {Cagliari, Italy},
series = {IUI '20}
}

@INPROCEEDINGS{9003747,  author={Cho, Eunah and Xie, He and Lalor, John P. and Kumar, Varun and Campbell, William M.},  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},   title={Efficient Semi-Supervised Learning for Natural Language Understanding by Optimizing Diversity},   year={2019},  volume={},  number={},  pages={1077-1084},  doi={10.1109/ASRU46091.2019.9003747}}


@inproceedings{10.1145/2818052.2869096,
author = {Kumar, Varun and Pedanekar, Niranjan},
title = {Mining Shapes of Expertise in Online Social Q&amp;A Communities},
year = {2016},
isbn = {9781450339506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2818052.2869096},
doi = {10.1145/2818052.2869096},
abstract = {Expertise of an individual is metaphorically defined by shapes of letters such as
I, T, M and hyphen, depending on her expertise in an area (depth) and the number of
areas of interest (width). Industries have now started recruiting people with specific
shapes of expertise. In this poster, we introduce the idea of mining shapes of user
expertise in a typical online social Question and Answer (Q&amp;A) community where expert
users often answer questions posed by other users. We report observations on distribution
of different shapes of expertise in a StackExchange community called Super User.},
booktitle = {Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing Companion},
pages = {317–320},
numpages = {4},
keywords = {Online Social Q&amp;A, Shapes of Expertise, Expertise Profiling, A Communities, Graph Mining},
location = {San Francisco, California, USA},
series = {CSCW '16 Companion}
}

@inproceedings{10.1145/3442188.3445924,
author = {Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
title = {BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445924},
doi = {10.1145/3442188.3445924},
selected={true},
abstract = {Recent advances in deep learning techniques have enabled machines to generate cohesive
open-ended text when prompted with a sequence of words as context. While these models
now empower many downstream applications from conversation bots to automatic storytelling,
they have been shown to generate texts that exhibit social biases. To systematically
study and benchmark social biases in open-ended language generation, we introduce
the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that
consists of 23,679 English text generation prompts for bias benchmarking across five
domains: profession, gender, race, religion, and political ideology. We also propose
new automated metrics for toxicity, psycholinguistic norms, and text gender polarity
to measure social biases in open-ended text generation from multiple angles. An examination
of text generated from three popular language models reveals that the majority of
these models exhibit a larger social bias than human-written Wikipedia text across
all domains. With these results we highlight the need to benchmark biases in open-ended
language generation and caution users of language generation models on downstream
tasks to be cognizant of these embedded prejudices.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {862–872},
numpages = {11},
keywords = {natural language generation, Fairness},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@INPROCEEDINGS{9383495,  author={Kumar, Manoj and Kumar, Varun and Glaude, Hadrien and de Lichy, Cyprien and Alok, Aman and Gupta, Rahul},  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)},   title={Protoda: Efficient Transfer Learning for Few-Shot Intent Classification},   year={2021},  volume={},  number={},  pages={966-972},  doi={10.1109/SLT48900.2021.9383495}}